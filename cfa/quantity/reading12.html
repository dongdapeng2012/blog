<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CFA Textbook</title>
</head>
<body>
	<h1>CFA Textbook</h1>
	--------------------
	<h1 id="session2">Study Session 2 Quantitative Methods : Basic
		Concepts</h1>
	--------------------
	<h2 id="reading12">Reading 12 Hypothesis Testing</h2>
	--------------------
	<h3>Summary</h3>
	<ul>
		<br />
		<li>A hypothesis is a statement about one or more populations.</li>
		<br />
		<li>The steps in testing a hypothesis are as follows:
			<ol type="1">
				<br />
				<li>Stating the hypotheses.</li>
				<br />
				<li>Identifying the appropriate test statistic and its
					probability distribution.</li>
				<br />
				<li>Specifying the significance level.</li>
				<br />
				<li>Stating the decision rule.</li>
				<br />
				<li>Collecting the data and calculating the test statistic.</li>
				<br />
				<li>Making the statistical decision.</li>
				<br />
				<li>Making the economic or investment decision.</li>
			</ol>
		</li>
		<br />
		<li>We state two hypotheses: The null hypothesis is the
			hypothesis to be tested; the alternative hypothesis is the hypothesis
			accepted when the null hypothesis is rejected.</li>
		<br />
		<li>There are three ways to formulate hypotheses:
			<ol type="1">
				<br />
				<li>H<sub>0</sub>: θ = θ<sub>0</sub> versus H<sub>a</sub>: θ ≠
					θ<sub>0</sub></li>
				<br />
				<li>H<sub>0</sub>: θ ≤ θ<sub>0</sub> versus H<sub>a</sub>: θ >
					θ<sub>0</sub></li>
				<br />
				<li>H<sub>0</sub>: θ ≥ θ<sub>0</sub> versus H<sub>a</sub>: θ <
					θ<sub>0</sub></li>
			</ol> <br />where θ<sub>0</sub> is a hypothesized value of the population
			parameter and θ is the true value of the population parameter. In the
			above, Formulation 1 is a two-sided test and Formulations 2 and 3 are
			one-sided tests.
		</li>
		<br />
		<li>When we have a “suspected” or “hoped for” condition for which
			we want to find supportive evidence, we frequently set up that
			condition as the alternative hypothesis and use a one-sided test. To
			emphasize a neutral attitude, however, the researcher may select a
			“not equal to” alternative hypothesis and conduct a two-sided test.</li>
		<br />
		<li>A test statistic is a quantity, calculated on the basis of a
			sample, whose value is the basis for deciding whether to reject or
			not reject the null hypothesis. To decide whether to reject, or not
			to reject, the null hypothesis, we compare the computed value of the
			test statistic to a critical value (rejection point) for the same
			test statistic.</li>
		<br />
		<li>In reaching a statistical decision, we can make two possible
			errors: We may reject a true null hypothesis (a Type I error), or we
			may fail to reject a false null hypothesis (a Type II error).</li>
		<br />
		<li>The level of significance of a test is the probability of a
			Type I error that we accept in conducting a hypothesis test. The
			probability of a Type I error is denoted by the Greek letter alpha,
			α. The standard approach to hypothesis testing involves specifying a
			level of significance (probability of Type I error) only.</li>
		<br />
		<li>The power of a test is the probability of correctly rejecting
			the null (rejecting the null when it is false).</li>
		<br />
		<li>A decision rule consists of determining the rejection points
			(critical values) with which to compare the test statistic to decide
			whether to reject or not to reject the null hypothesis. When we
			reject the null hypothesis, the result is said to be statistically
			significant.</li>
		<br />
		<li>The (1 − α) confidence interval represents the range of
			values of the test statistic for which the null hypothesis will not
			be rejected at an α significance level.</li>
		<br />
		<li>The statistical decision consists of rejecting or not
			rejecting the null hypothesis. The economic decision takes into
			consideration all economic issues pertinent to the decision.</li>
		<br />
		<li>The p-value is the smallest level of significance at which
			the null hypothesis can be rejected. The smaller the p-value, the
			stronger the evidence against the null hypothesis and in favor of the
			alternative hypothesis. The p-value approach to hypothesis testing
			does not involve setting a significance level; rather it involves
			computing a p-value for the test statistic and allowing the consumer
			of the research to interpret its significance.</li>
		<br />
		<li>For hypothesis tests concerning the population mean of a
			normally distributed population with unknown (known) variance, the
			theoretically correct test statistic is the t-statistic
			(z-statistic). In the unknown variance case, given large samples
			(generally, samples of 30 or more observations), the z-statistic may
			be used in place of the t-statistic because of the force of the
			central limit theorem.</li>
		<br />
		<li>The t-distribution is a symmetrical distribution defined by a
			single parameter: degrees of freedom. Compared to the standard normal
			distribution, the t-distribution has fatter tails.</li>
		<br />
		<li>When we want to test whether the observed difference between
			two means is statistically significant, we must first decide whether
			the samples are independent or dependent (related). If the samples
			are independent, we conduct tests concerning differences between
			means. If the samples are dependent, we conduct tests of mean
			differences (paired comparisons tests).</li>
		<br />
		<li>When we conduct a test of the difference between two
			population means from normally distributed populations with unknown
			variances, if we can assume the variances are equal, we use a t-test
			based on pooling the observations of the two samples to estimate the
			common (but unknown) variance. This test is based on an assumption of
			independent samples.</li>
		<br />
		<li>When we conduct a test of the difference between two
			population means from normally distributed populations with unknown
			variances, if we cannot assume that the variances are equal, we use
			an approximate t-test using modified degrees of freedom given by a
			formula. This test is based on an assumption of independent samples.</li>
		<br />
		<li>In tests concerning two means based on two samples that are
			not independent, we often can arrange the data in paired observations
			and conduct a test of mean differences (a paired comparisons test).
			When the samples are from normally distributed populations with
			unknown variances, the appropriate test statistic is a t-statistic.
			The denominator of the t-statistic, the standard error of the mean
			differences, takes account of correlation between the samples.</li>
		<br />
		<li>In tests concerning the variance of a single, normally
			distributed population, the test statistic is chi-square (χ<sup>2</sup>)
			with n − 1 degrees of freedom, where n is sample size.
		</li>
		<br />
		<li>For tests concerning differences between the variances of two
			normally distributed populations based on two random, independent
			samples, the appropriate test statistic is based on an F-test (the
			ratio of the sample variances).</li>
		<br />
		<li>The F-statistic is defined by the numerator and denominator
			degrees of freedom. The numerator degrees of freedom (number of
			observations in the sample minus 1) is the divisor used in
			calculating the sample variance in the numerator. The denominator
			degrees of freedom (number of observations in the sample minus 1) is
			the divisor used in calculating the sample variance in the
			denominator. In forming an F-test, a convention is to use the larger
			of the two ratios, s<sup>2</sup><sub style="margin: 0 0 0 -5px;">1</sub>
			/ s<sup>2</sup><sub style="margin: 0 0 0 -5px;">2</sub> or s<sup>2</sup><sub
			style="margin: 0 0 0 -5px;">2</sub> / s<sup>2</sup><sub
			style="margin: 0 0 0 -5px;">1</sub> , as the actual test statistic.
		</li>
		<br />
		<li>A parametric test is a hypothesis test concerning a parameter
			or a hypothesis test based on specific distributional assumptions. In
			contrast, a nonparametric test either is not concerned with a
			parameter or makes minimal assumptions about the population from
			which the sample comes.</li>
		<br />
		<li>A nonparametric test is primarily used in three situations:
			when data do not meet distributional assumptions, when data are given
			in ranks, or when the hypothesis we are addressing does not concern a
			parameter.</li>
		<br />
		<li>The Spearman rank correlation coefficient is calculated on
			the ranks of two variables within their respective samples.</li>
	</ul>
	<br />
	<h3>中文手册整理</h3>
	<ul>
		<br />
		<li></li>
		<br />
		<li></li>
		<br />
		<li></li>
	</ul>
	--------------------
</body>
</html>